---
title: "Exploratory Analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The SQLite database `dressage.db` contains the cleaned pedigree and show data in the tables `clean_pedigree` and `clean_shows`, respectively. 

``` {r}
library(tidyverse)
library(RSQLite)

conn <- dbConnect(RSQLite::SQLite(), "dressage.db")

ped <- dbGetQuery(conn,'SELECT * FROM clean_pedigree')
shows <- dbGetQuery(conn, 'SELECT * FROM clean_shows')
```

In this exploratory analyses, I want to better understand how well sires and riders are represented in my data, examine the data for covariates, explore and deal with any missing data, and come up with a model.

``` {r}
summary(ped)

for (iii in c("horse_id", "horse_ueln", "sire", "sex")) {
  ped[[iii]] <- as.factor(ped[[iii]])
}

ped$yob <- as.numeric(ped$yob)

summary(shows)

for (iii in c("horse_id", "sex", "rider_id")) {
  shows[[iii]] <- as.factor(shows[[iii]])
}

for (iii in c("score", "yob")) {
  shows[[iii]] <- as.numeric(shows[[iii]])
}
```

## Summary Information

The dataset contains information on 1031 horses, with 14,871 show records available on 681 of these horses. 843 horses have sire information available, and are descended from 183 sires. The show data has results for 664 riders. I create a new column, `combination` which represents the combination of horse and rider. There are 899 horse/rider combinations in the data, thus in some cases the same rider must ride multiple horses.

``` {r summary stats}
nrow(ped)
nrow(shows)
sum(!is.na(ped$sire))
length(unique(ped$sire))
length(unique(shows$horse_id))
length(unique(shows$rider_id))

shows$combination <- paste0(shows$rider_id, shows$horse_id)

length(unique(shows$combination))
```

## Creating a Measure of Success

I am interested in using this dataset to explore what factors influence success in dressage horses. So first, I need to use the available data to create a measure of success. This will be derived from the show `score`. This data has a single outlier of `score` 0 and 413 NAs. Given that 0 is an impossible score, I simply omit this outlier.

``` {r outliers}
summary(shows$score)

shows <- shows %>%
  filter(score > 0 | is.na(score))

hist(shows$score)
```

As I established when cleaning the data, most of the NAs represent failure to complete the test (DSQ = disqualified, WD = withdrawn, RET = retired, EL = eliminated). These classifications are never associated with a non-NA score. Only 55 NAs are not explained by failure to complete the test (out of 14,870 shows). I want to know whether these are randomly missing, or associated with any other feature of the data (e.g. horse, rider, show type). All shows with NA in both `score` and `position` were attributed to a single horse, id SWE04871, and these are the only shows listed for this individual. Thus, I am forced to omit this individual. 

``` {r missing scores}
shows %>%
  filter((position %in% c("DSQ", "EL", "RET", "WD"))) %>%
  count(score)

shows %>%
  filter(is.na(score)) %>%
  filter(!(position %in% c("DSQ", "EL", "RET", "WD"))) %>%
  count(horse_id)

shows %>%
  filter(is.na(position) & is.na(score)) %>%
  count(horse_id)

shows %>%
  filter(horse_id == "SWE04871") %>%
  count()

shows <- shows %>%
  filter(horse_id != "SWE04871")

ped <- ped %>%
  filter(horse_id != "SWE04871")
```

The remaining 5 NA scores are attributable to just two other horses, ids GER43431 and NED04088. Unlike SWE04871, these horses have plenty of other non-NA shows. Three of these were "historical rules", and are the only "historical rules" in the dataset. I could not find any further information on the meaning of this classification, but I assume that it will not be relevant to my analyses, and thus omit them. The other shows are freestyle to music, but there are plenty of these shows with non-NA score entries (~2500). Both shows were competed by the same rider/horse combination, but this combination has 25 other results. Given the massive scale of this data, which is otherwise complete, I feel that it is safe to omit these two datapoints, although I cannot explain why they are missing. 

``` {r}
shows %>% 
  filter(horse_id %in% c("GER43431", "NED04088")) %>%
  count(horse_id)

shows %>%
  filter(is.na(score)) %>%
  filter(!(position %in% c("DSQ", "EL", "RET", "WD"))) %>%
  count(comp_title)

shows[str_detect(shows$comp_title, "Hist"),]

shows <- shows %>%
  filter(!comp_title == "Hist - Historical Rule")

nrow(shows[str_detect(shows$comp_title, "Music"),])

shows %>%
  filter(is.na(score)) %>%
  filter(!(position %in% c("DSQ", "EL", "RET", "WD"))) 

shows %>%
  filter(rider_id == "10019451" & horse_id == "GER43431")

shows <- shows %>%
  filter(!is.na(score) | (position %in% c("DSQ", "EL", "RET", "WD")))

shows %>%
  filter(is.na(score) & !(position %in% c("RET", "WD", "EL", "DSQ")))
```

I want `score` to be a continuous variable for analysis. This raises the question of how to represent the various categories of non-completion in `score`. I believe that failing to complete a show due to elimination or disqualification should inevitably be detrimental to a combination's measure of success as they indicate that the combination performed poorly in that show. Retirement and withdrawal are slightly less clear, because they may not necessarily represent poor performance. For example, a rider may choose to retire when they realise they cannot beat the current leading score, but that doesn't necessarily mean their performance was bad, just not good enough to take home a trophy. Withdrawal may occur due to some irrelevant circumstances, such as illness.

Thus, at least to start with, I propose two crude imputations of these categories. Shows marked WD or RET will be assigned a score randomly drawn from a normal distribution (68.81511, 3.269806). The score shows are approximately normally distributed, so this distribution seems appropriate. I have overlayed this distribution (green) over the true distribution (black) in the graph below. Essentially, we are assuming that withdrawal or retirement means that a combination is less likely than normal to have achieved an especially high score, but on the whole their scores are similar to that of other shows. I choose to sample shows from a distribution rather than assign a single value, because I do not want to compromise the variance or normality of my data. 

``` {r impute WD and RET}
wd_ret_mean <- mean(shows$score, na.rm = T) - 1
wd_ret_sd <- sd(shows$score, na.rm = T)/1.5

wd_ret_points <- seq(-4, 4, length = 100) * wd_ret_sd + wd_ret_mean
wd_ret_dist <- dnorm(wd_ret_points, wd_ret_mean, wd_ret_sd)

ggplot() +
  geom_point(aes(x = wd_ret_points, y = wd_ret_dist), color = "green") + 
  geom_freqpoly(data = shows, aes(x = score), stat = "density") + 
  xlab("Score") +
  ylab("Probability or Frequency")
```

On the other hand, I want to penalise individuals who are eliminated (EL) or disqualified (DSQ). Thus, I impute values from a normal distribution (66.56, 4.904709). The mean of this distribution is the 25th percentile of the data. Thus, I am penalising combinations for having been eliminated or disqualified. 

``` {r impute EL and DSQ}
quantile(shows$score, probs = 0.25, na.rm = T)
el_dsq_mean <- 66.565
el_dsq_sd <- sd(shows$score, na.rm = T)/1.5

el_dsq_points <- seq(-4, 4, length = 100) * el_dsq_sd + el_dsq_mean
el_dsq_dist <- dnorm(el_dsq_points, el_dsq_mean, el_dsq_sd)

ggplot() +
  geom_point(aes(x = el_dsq_points, y = el_dsq_dist), color = "green") + 
  geom_freqpoly(data = shows, aes(x = score), stat = "density") + 
  xlab("Score") +
  ylab("Probability or Frequency")
```

## Relatedness

## Covariates

``` {r}
plot(score~yob, data = shows)
```

## Missingness

## Designing the Model
